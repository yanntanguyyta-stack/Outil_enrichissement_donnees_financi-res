# ðŸ“¦ Guide du Traitement par Lots OptimisÃ©

## Vue d'ensemble

Le systÃ¨me de traitement par lots optimisÃ© permet de traiter efficacement **des fichiers volumineux contenant des centaines d'entreprises** tout en respectant les contraintes d'espace disque limitÃ©.

## ðŸŽ¯ ProblÃ¨me rÃ©solu

### Contraintes
- âœ… Espace disque limitÃ© (~30 GB total)
- âœ… Fichiers RNE de ~2-3 MB chacun (1380 fichiers disponibles)
- âœ… Besoin de traiter potentiellement des centaines d'entreprises

### Solution
**Traitement par lots avec nettoyage automatique** :
1. Grouper les entreprises par fichier RNE nÃ©cessaire
2. TÃ©lÃ©charger et traiter par lots
3. Supprimer automatiquement aprÃ¨s traitement
4. ParallÃ©liser (3 fichiers RNE max simultanÃ©ment)

## ðŸš€ Fonctionnement

### Activation automatique

Le mode batch s'active **automatiquement** quand :
- âœ… Nombre d'entreprises â‰¥ 50
- âœ… Enrichissement RNE activÃ© dans la sidebar
- âœ… Module `enrichment_hybrid.py` disponible

### Les 3 phases

#### ðŸ“Š Phase 1 : Identification (API DINUM)
```
Pour chaque entreprise :
  â†’ Recherche via API DINUM
  â†’ RÃ©cupÃ©ration du SIREN
  â†’ Stockage temporaire en mÃ©moire
```

**Affichage** : Barre de progression + nombre traitÃ©

#### ðŸ“¦ Phase 2 : Regroupement optimal
```
Algorithme de groupement :
  1. Charger l'index lÃ©ger (213 KB)
  2. Pour chaque SIREN :
     â†’ Recherche binaire O(log n) dans l'index
     â†’ Identifier le fichier RNE correspondant
  3. Grouper : {fichier_RNE: [siren1, siren2, ...]}
```

**RÃ©sultat** : Carte `filename â†’ liste de SIRENs`

#### âš¡ Phase 3 : Traitement parallÃ¨le
```python
with ThreadPoolExecutor(max_workers=3):
    Pour chaque fichier RNE en parallÃ¨le :
      1. TÃ©lÃ©charger (FTP INPI, ~7 secondes)
      2. Extraire les bilans des SIRENs du lot
      3. Formatter les donnÃ©es
      4. SUPPRIMER le fichier du cache
      5. Continuer avec le prochain lot
```

**Avantages** :
- ðŸ’¾ Maximum 3 fichiers RNE en mÃ©moire (â‰ˆ 7.5 MB)
- âš¡ ParallÃ©lisation : gain de 66% de temps
- ðŸ—‘ï¸ Nettoyage automatique : pas de saturation disque

## ðŸ“Š Performances

### Exemple : 100 entreprises

**RÃ©partition typique** :
- 8 fichiers RNE diffÃ©rents
- 12-13 entreprises par fichier en moyenne

**Temps de traitement** :
| Mode | Temps | DÃ©tail |
|------|-------|--------|
| SÃ©quentiel | ~56s | 8 fichiers Ã— 7s |
| ParallÃ¨le (3 workers) | ~19s | âŒˆ8/3âŒ‰ Ã— 7s |
| **Gain** | **66%** | 37s gagnÃ©es |

**Espace disque** :
| Mode | Stockage |
|------|----------|
| Tout tÃ©lÃ©charger | ~20 MB (8 fichiers) |
| Par lots (3 max) | ~7.5 MB (3 fichiers) |
| **Ã‰conomie** | **62%** |

### Exemple : 500 entreprises

**RÃ©partition typique** :
- 35 fichiers RNE diffÃ©rents
- 14-15 entreprises par fichier

**Temps** :
- SÃ©quentiel : ~245s (4 min)
- ParallÃ¨le : ~82s (1.4 min)
- **Gain : 66%**

**Espace** :
- Maximum : ~7.5 MB (3 fichiers simultanÃ©s)
- Pas de saturation possible

## ðŸŽ¨ Interface utilisateur

### Sidebar : Activation

```
ðŸ›ï¸ Enrichissement RNE
â˜‘ Activer enrichissement FTP/RNE

âœ… Enrichissement RNE activÃ©
ðŸ“ˆ DonnÃ©es sur plusieurs annÃ©es
ðŸ’¾ Cache local (rapide)
ðŸ”„ TÃ©lÃ©chargement Ã  la demande

ðŸš€ Mode optimisÃ© pour gros volumes
Ã€ partir de 50 entreprises :
- ðŸ“¦ Tri par fichiers RNE
- âš¡ Traitement parallÃ¨le (3 fichiers max)
- ðŸ—‘ï¸ Nettoyage automatique
- ðŸ’¾ Ã‰conomie d'espace disque
```

### Affichage pendant le traitement

**Mode batch activÃ©** :
```
ðŸš€ Mode d'optimisation activÃ© pour 150 entreprises

Traitement par lots optimisÃ© :
- ðŸ“Š Phase 1: RÃ©cupÃ©ration des SIRENs via API DINUM
- ðŸ“¦ Phase 2: Tri et regroupement par fichier RNE
- âš¡ Phase 3: TÃ©lÃ©chargement parallÃ¨le (3 fichiers max simultanÃ©s)
- ðŸ—‘ï¸ Nettoyage automatique aprÃ¨s chaque lot

ðŸ“Š Phase 1: Identification des entreprises
Recherche 73/150: Entreprise ABC...
[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 48%

ðŸ“¦ Phase 2-3: Enrichissement RNE par lots
ðŸ“¦ Fichiers traitÃ©s: 8/23 - Actuel: stock_000145.json
[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 35%

âœ… Traitement terminÃ© : 150 entreprises traitÃ©es
```

## ðŸ”§ Configuration

### ParamÃ¨tres dans `enrichment_hybrid.py`

```python
# Nombre max de fichiers RNE tÃ©lÃ©chargÃ©s simultanÃ©ment
MAX_CONCURRENT_FILES = 3

# Taille moyenne d'un fichier RNE (pour estimation)
AVG_RNE_FILE_SIZE_MB = 2.5
```

### ParamÃ¨tres dans `app.py`

```python
# Seuil d'activation du mode batch
BATCH_THRESHOLD = 50  # Minimum entreprises pour activer
```

### Personnalisation

Pour ajuster selon vos besoins :

**Plus de performance (+ espace disque)** :
```python
MAX_CONCURRENT_FILES = 3
LIMITED_SPACE_MODE = False
# NÃ©cessite ~240 MB de cache (3 Ã— 80 MB)
```

**Moins d'espace disque (mode actuel, recommandÃ©)** :
```python
MAX_CONCURRENT_FILES = 1  # 1 fichier Ã  la fois
LIMITED_SPACE_MODE = True  # Nettoyage agressif
# Seulement ~80 MB de cache temporaire
# + 84 fichiers de base (000001-000084) = 5.2 GB pÃ©rennes
```

## ðŸ“‹ API du module

### Fonctions principales

#### `group_sirens_by_rne_file(sirens: List[str]) -> Dict[str, List[str]]`
Groupe les SIRENs par fichier RNE.

```python
sirens = ["552100554", "005880596", "775665019"]
grouped = group_sirens_by_rne_file(sirens)
# {
#   "stock_000498.json": ["552100554"],
#   "stock_000001.json": ["005880596"],
#   "stock_000534.json": ["775665019"]
# }
```

#### `process_batch(filename, sirens, max_bilans=10, cleanup=True) -> Dict`
Traite un lot de SIRENs depuis un mÃªme fichier RNE.

```python
results = process_batch(
    "stock_000498.json",
    ["552100554"],
    max_bilans=10,
    cleanup=True  # Supprimer aprÃ¨s traitement
)
```

#### `enrich_batch_parallel(sirens, max_bilans=10, max_workers=3, progress_callback=None) -> Dict`
Enrichissement parallÃ¨le optimisÃ©.

```python
def progress(completed, total, current_file):
    print(f"{completed}/{total}: {current_file}")

results = enrich_batch_parallel(
    sirens=["552100554", "005880596"],
    max_bilans=10,
    max_workers=3,
    progress_callback=progress
)
```

## ðŸ§ª Tests

### Lancer les tests

```bash
python3 test_batch_processing.py
```

**Tests disponibles** :
1. âœ… Regroupement par fichier RNE
2. âœ… Traitement d'un lot unique (nÃ©cessite FTP)
3. âœ… Traitement parallÃ¨le (nÃ©cessite FTP)
4. âœ… Simulation gros volume (sans FTP)

### Tests unitaires rapides

```bash
# Test sans connexion FTP
python3 test_batch_processing.py <<< "n"

# Test complet avec FTP
python3 test_batch_processing.py <<< "o"
```

## ðŸ’¡ Conseils d'utilisation

### Pour des fichiers trÃ¨s volumineux (1000+ entreprises)

1. **Utilisez le mode RNE activÃ©** pour bÃ©nÃ©ficier du batch
2. **Laissez le temps** : ~1-2 min par 100 entreprises
3. **Surveillez l'espace disque** : reste stable (~7 MB cache)
4. **Exportez rÃ©guliÃ¨rement** les rÃ©sultats

### Limitation de l'API DINUM

- 250 requÃªtes / minute
- DÃ©lai appliquÃ© : 0.5s entre requÃªtes
- 100 entreprises = ~50s phase 1

### En cas de problÃ¨me

**Erreur "Limit API atteinte"** :
- Le systÃ¨me retry automatiquement (backoff exponentiel)
- Maximum 3 tentatives par entreprise

**Fichier RNE non trouvÃ©** :
- VÃ©rifiez la connexion FTP
- Certains SIRENs peuvent Ãªtre hors limites RNE

**Manque d'espace** :
- RÃ©duire `MAX_CONCURRENT_FILES` Ã  2
- VÃ©rifier `/workspaces` : `df -h`

## ðŸŽ“ Algorithme dÃ©taillÃ©

### ComplexitÃ©

| OpÃ©ration | ComplexitÃ© |
|-----------|------------|
| Recherche dans index | O(log n) par SIREN |
| Groupement | O(m Ã— log n), m=nb SIRENs |
| TÃ©lÃ©chargement | O(k/w), k=fichiers, w=workers |
| Extraction | O(m) |
| **Total** | **O(m Ã— log n + k/w + m)** |

Pour 100 entreprises :
- m = 100 SIRENs
- n = 1380 fichiers (index)
- k â‰ˆ 8 fichiers RNE
- w = 3 workers

â†’ O(100 Ã— 11 + 3 + 100) â‰ˆ O(1203) opÃ©rations

### Pseudo-code complet

```python
def traiter_fichier_volumineux(fichier_csv):
    # Phase 1: Identification
    sirens_map = {}
    for entreprise in fichier_csv:
        data = api_dinum.recherche(entreprise.nom)
        if data.siren:
            sirens_map[data.siren] = (data, entreprise)
    
    # Phase 2: Groupement optimal
    index = charger_index_ranges()  # 213 KB
    groupes = {}
    for siren in sirens_map.keys():
        fichier_rne = recherche_binaire(siren, index)
        groupes[fichier_rne].append(siren)
    
    # Phase 3: Traitement parallÃ¨le
    resultats = {}
    with ThreadPool(workers=3) as pool:
        futures = []
        for fichier_rne, sirens_lot in groupes.items():
            future = pool.submit(
                telecharger_traiter_nettoyer,
                fichier_rne,
                sirens_lot
            )
            futures.append(future)
        
        for future in as_completed(futures):
            resultats.update(future.result())
    
    return resultats

def telecharger_traiter_nettoyer(fichier, sirens):
    # TÃ©lÃ©charger
    data = ftp.download(fichier)  # ~7s
    
    # Traiter
    bilans = {}
    for siren in sirens:
        bilans[siren] = extraire_bilans(data, siren)
    
    # Nettoyer (crucial!)
    os.remove(cache / fichier)
    
    return bilans
```

## ðŸ“š RÃ©fÃ©rences

- **Index RNE** : [rne_siren_ranges.json](rne_siren_ranges.json) (213 KB)
- **Module** : [enrichment_hybrid.py](enrichment_hybrid.py)
- **Tests** : [test_batch_processing.py](test_batch_processing.py)
- **Guide stockage** : [GUIDE_STOCKAGE_RNE.md](GUIDE_STOCKAGE_RNE.md)

## ðŸŽ‰ RÃ©sumÃ©

Le traitement par lots optimisÃ© vous permet de :

- âœ… **Traiter des centaines d'entreprises** sans saturer le disque
- âœ… **Gagner 66% de temps** grÃ¢ce Ã  la parallÃ©lisation
- âœ… **Ã‰conomiser 62% d'espace** avec le nettoyage automatique
- âœ… **Interface simple** : activation automatique dÃ¨s 50 entreprises
- âœ… **Robustesse** : retry automatique, gestion d'erreurs

**Mode d'emploi** : Uploadez votre fichier CSV, activez l'enrichissement RNE, et laissez le systÃ¨me optimiser automatiquement ! ðŸš€
